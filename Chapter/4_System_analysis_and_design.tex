\documentclass[../Main.tex]{subfiles}
\usepackage{calc}

\begin{document}
	This section provides a comprehensive analysis and design overview of \emph{\textbf{four
	pivotal systems}} introduced in the Chapter \ref{chapter:Preface}: Preface.
	Each system is meticulously examined to elucidate its architectural framework,
	design principles, and functional components. The analysis aims to offer a detailed
	understanding of how these systems are structured to achieve their intended objectives,
	ensuring scalability, maintainability, and integration capabilities. By focusing
	on the core design elements and interdependencies, this section lays the
	groundwork for understanding the intricate workings of each system, setting the
	stage for their subsequent implementation and deployment.
	
	\section{Deployment Architecture}
	\label{section:4.5_deployment_architecture} Figure~\ref{fig:Deployment_Diagram}
	presents the deployment architecture of the system, showing the physical distribution
	of major components across two main servers:

	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\textwidth]{Figure/Deployment Diagram0.png}
		\caption{Deployment Diagram of the E-learning System}
		\label{fig:Deployment_Diagram}
	\end{figure}

	The \textbf{Agent Server} (GPU Server) hosts the \fcolorbox{gray!50}{gray!10}{\texttt{Agent System}}, including the
	\fcolorbox{gray!50}{gray!10}{\texttt{AgenticWorkflow}}, \fcolorbox{gray!50}{gray!10}{\texttt{InferenceProvider}}, and \fcolorbox{gray!50}{gray!10}{\texttt{RetrievalService}} sub-systems. These components
	leverage GPU resources for efficient model inference and advanced retrieval tasks.
	The \textbf{ELearning Server} (Hosting Server) runs the OpenEdX backend and FrontendService,
	providing core learning management and user interface functionalities. Communication
	between the Agent System and OpenEdX backend enables intelligent assistance and
	integration of AI-driven features. This deployment ensures that compute-intensive
	AI services are isolated on specialized hardware, supporting scalability and efficient
	resource utilization, while the core e-learning platform remains stable and
	maintainable on standard hosting infrastructure.
	
	\section{AI System Architecture}
	\label{section:4.1_ai_system_architecture}
	\subsection{The Role of the Subsystem}
	\label{section:4.1.1_the_role_of_the_subsystem}
	\begin{condensed_idea}[The Role of the AI System within the Thesis]
		The AI System, situated within the AI System layer of the Section \ref{section:1.3_Tentative_solution}: Tentative Solution (Chapter \ref{chapter:Preface}: Preface), serves as a pivotal component in the orchestration of intelligent agentic workflows. This subsystem is meticulously designed to integrate the main agentic workflow component, developed using the proposed framework (Chapter \ref{chapter:Theoretical_foundation_of_agentic_workflow_framework}), alongside a suite of sophisticated tools tailored for agents, including but not limited to Retrieval-Augmented Generation (RAG) for knowledge retrieval and Model Context Protocol (MCP) for tool integration.
	\end{condensed_idea}
	The primary function of the AI Agent System is to facilitate seamless
	interaction and coordination among various agentic processes, thereby enhancing
	the system's overall capability to perform complex reasoning and decision-making
	tasks. By leveraging the modular architecture of the agentic workflow, the system
	ensures adaptability and scalability, allowing for the dynamic incorporation
	of new tools and methodologies as the field of artificial intelligence evolves.
	Furthermore, the AI Agent System is instrumental in enabling agents to execute
	tasks with a high degree of autonomy and efficiency. Through the integration of
	advanced retrieval and processing tools, the system empowers agents to access
	and synthesize information from diverse sources, thereby augmenting their ability
	to provide accurate and contextually relevant responses. This capability is
	crucial for applications requiring sophisticated problem-solving and knowledge
	discovery, positioning the AI Agent System as a cornerstone of the intelligent
	agent framework.

	\subsection{Overall Design}
	\label{section:4.1.2_overall_design} The \fcolorbox{gray!50}{gray!10}{\texttt{AgentSystem}} Component constitutes the
	core of the intelligent agent framework, orchestrating advanced reasoning, retrieval,
	and tool integration capabilities to support automated question answering and
	intelligent search over learning materials. As depicted in Figure~\ref{fig:AgentSystem_Component_Diagram},
	the AgentSystem is architected as a modular microservice, comprising four principal
	sub-systems: \emph{\textbf{Retrieval Service}}, \emph{\textbf{Tool Ecosystem}},
	\emph{\textbf{Agentic Workflow}}, and \emph{\textbf{Inference Provider}}. Each
	sub-system is designed to encapsulate a distinct set of responsibilities, ensuring
	scalability, maintainability, and extensibility.

	\begin{figure}[H]
		\centering
		\includegraphics[angle=90, height=0.8\textheight]{Figure/AI Subsystem.png}
		\caption{AgentSystem Component Diagram}
		\label{fig:AgentSystem_Component_Diagram}
	\end{figure}

	\subsubsection{Component Description and Dependencies}
	\label{section:4.1.2.1_component_description_and_dependencies} The system's
	architecture is built around four core components, each with specific responsibilities
	and dependencies:

	\begin{itemize}
		\item \textbf{Retrieval Service:} Handles all document and memory retrieval
			operations, depending on the Inference Provider for embedding generation and
			LLM services.

		\item \textbf{Tool Ecosystem:} Manages external tool execution and
			integration, depending on the Retrieval Service for document and memory access.

		\item \textbf{Agentic Workflow:} Orchestrates agent operations and workflow
			execution, depending on both the Tool Ecosystem and Retrieval Service.

		\item \textbf{Inference Provider:} Provides model inference capabilities, serving
			as a foundational service for other components.
	\end{itemize}

	\subsubsection{Interface and Communication Patterns}
	\label{section:4.1.2.2_interface_and_communication_patterns} The system
	implements a service-oriented architecture with well-defined interfaces:

	\begin{itemize}
		\item \textbf{MemoryRetrieval:} Interface for accessing and updating agent
			memory

		\item \textbf{DocumentRetrieval:} Interface for document search and
			management

		\item \textbf{ToolCall:} Standardized interface for tool invocation

		\item \textbf{AgentResponse:} Interface for agent communication and response
			handling
	\end{itemize}

	\subsubsection{Architectural Design Principles}
	\label{section:4.1.2.3_architectural_design_principles} The architecture adheres
	to several key design principles:

	\begin{itemize}
		\item \textbf{Modularity:} Each sub-system is designed as an independent
			module with clear boundaries

		\item \textbf{Scalability:} Components can be scaled independently based on
			demand

		\item \textbf{Extensibility:} New capabilities can be added through
			standardized interfaces

		\item \textbf{Maintainability:} Clear separation of concerns and well-defined
			interfaces

		\item \textbf{Reliability:} Robust error handling and failover mechanisms
	\end{itemize}

	\subsection{Detailed Component Design}
	\label{section:4.1.3_detailed_component_design}
	\subsubsection{Retrieval Service}
	\label{section:4.1.3.1_retrieval_service} The Retrieval Service sub-system is
	responsible for all retrieval-related tasks, including document search, memory
	search, and hybrid retrieval workflows. It integrates multiple storage
	backends and retrieval strategies to support both semantic and symbolic search:

	\begin{itemize}
		\item \textbf{Document Retrieval and Update:} Manages indexing, updating,
			and searching of textual documents using vector databases (e.g., Qdrant,
			Elasticsearch, Infinity) and graph databases (e.g., Neo4j, NebulaGraph).
			Supports both dense (vector-based) and symbolic (graph-based) retrieval.

		\item \textbf{Memory Retrieval and Update:} Handles the storage and
			retrieval of agentic memory, enabling context-aware reasoning and persistent
			conversational state.

		\item \textbf{RAGFlow:} Implements RAG
			pipelines, orchestrating the flow between retrieval modules and downstream
			language models.

		\item \textbf{Embedding Service:} Provides embedding generation for queries
			and documents, supporting semantic search and similarity computation.

		\item \textbf{LLM Service Integration:} Interfaces with language models for
			query expansion, reranking, and answer synthesis.

		\item \textbf{OCR and Document Processing:} Integrates with OCR modules (e.g.,
			Surya) to enable retrieval from scanned or image-based documents.
	\end{itemize}

	\subsubsection{Tool Ecosystem}
	\label{section:4.1.3.2_tool_ecosystem} The Tool Ecosystem sub-system manages the
	execution and integration of external tools, enabling the agent to perform
	complex operations beyond pure language understanding:

	\begin{itemize}
		\item \textbf{Tool Execution:} Provides a unified interface for invoking a
			wide range of tools, including code execution, data processing, and third-party
			APIs.

		\item \textbf{MCP Portal and MCP Converter:} Facilitates communication with
			external tool servers and converts tool responses into agent-compatible
			formats.

		\item \textbf{OpenAPI Integration:} Supports dynamic tool discovery and
			invocation via OpenAPI specifications, enabling extensibility and interoperability.

		\item \textbf{Memory and Document Retrieval Integration:} Seamlessly
			connects with the Retrieval Service to provide tools with access to
			relevant documents and memory.
	\end{itemize}

	\subsubsection{Inference Provider}
	\label{section:4.1.3.4_inference_provider} The Inference Provider sub-system abstracts
	and manages access to various model inference services, supporting both local
	and remote model deployments:

	\begin{itemize}
		\item \textbf{LLM Service:} Provides access to large language models (e.g., vLLM)
			for text generation, reasoning, and dialogue.

		\item \textbf{Embedding Service:} Offers embedding generation for semantic
			search and retrieval tasks.

		\item \textbf{Inference Service:} Manages model selection, load balancing,
			and failover across multiple inference backends (e.g., xInference).
	\end{itemize}

	This architecture enables the \fcolorbox{gray!50}{gray!10}{\texttt{AgentSystem}} to efficiently orchestrate complex,
	multi-step reasoning and tool-augmented workflows, providing robust support for
	advanced e-learning functionalities such as automated question answering,
	personalized content retrieval, and dynamic tool integration.

	\subsubsection{Agentic Workflow}
	\label{section:4.1.3.3_agentic_workflow} The Agentic Workflow sub-system is responsible
	for the execution of agentic operators, management of the agentic supernet, and
	short-term memory:

	\begin{itemize}
		\item \textbf{Supernet Execution:} Implements the agentic workflow creation
			framework (see Chapter~\ref{chapter:Theoretical_foundation_of_agentic_workflow_framework}), dynamically composing and
			executing multi-agent workflows based on the supernet architecture.

		\item \textbf{Agentic Operator Execution:} Manages the invocation and
			coordination of individual agentic operators, each of which may involve multiple
			LLM calls and tool usages.

		\item \textbf{Short-term Memory Management:} Maintains a context window of
			recent interactions, supporting context-aware reasoning and efficient memory
			retrieval.

		\item \textbf{Interface Management:} Exposes standardized interfaces (ToolCall,
			AgentResponse) for communication with other system components.
	\end{itemize}

	\subsubsection{Agentic Workflow Class Diagram}
	\label{section:4.1.3.4_agentic_workflow_class_diagram}

	The Agentic Workflow Class Diagram (Figure~\ref{fig:Agentic_Workflow_Class_Diagram})
	illustrates the high-level architecture of the agentic workflow system,
	organized into four main packages: \fcolorbox{gray!50}{gray!10}{\texttt{Model Loading}}, \fcolorbox{gray!50}{gray!10}{\texttt{Base Graph}},
	\fcolorbox{gray!50}{gray!10}{\texttt{Supernet}}, and \fcolorbox{gray!50}{gray!10}{\texttt{Short-term Memory}}. Each package encapsulates a
	distinct aspect of the system, promoting modularity, reusability, and
	maintainability.

	\paragraph{Model Loading}
	The \textbf{Model Loading} package is responsible for the initialization and
	configuration of core system components, including large language models (LLMs),
	embedding models, NLP models, and tools. Each of these components is abstracted
	as a \texttt{SystemComponent}, and each has a dedicated configuration class (\texttt{LLMConfig},
	\texttt{EmbeddingConfig}, \texttt{NLPConfig}, \texttt{ToolConfig}). This design
	offers several advantages:
	\begin{itemize}
		\item \textbf{Separation of Concerns:} By isolating configuration logic into
			dedicated classes, the system avoids the pitfalls of monolithic configuration
			files (such as a single \.env file). This makes the codebase cleaner and easier
			to manage.

		\item \textbf{Reusability:} Configuration classes can be reused across
			different projects or components, facilitating code reuse and reducing duplication.

		\item \textbf{Extensibility:} New system components or configuration options
			can be added with minimal impact on existing code.

		\item \textbf{Integration with Langchain:} Leveraging Langchain for model
			loading allows the system to benefit from a robust, community-supported framework
			while retaining the flexibility to extend or customize as needed.
	\end{itemize}
	\paragraph{Base Graph}
	The \textbf{Base Graph} package provides a minimal, efficient implementation of
	a graph structure, consisting of \texttt{GraphNode} and \texttt{GraphEdge}
	classes, managed by a \texttt{BaseGraph} class. The decision to implement a custom
	graph, rather than relying on existing libraries, is motivated by the following
	considerations:
	\begin{itemize}
		\item \textbf{Simplicity:} Many third-party graph libraries offer extensive
			features that are unnecessary for this application, potentially introducing
			unwanted complexity and overhead.

		\item \textbf{Efficiency:} A custom, minimal implementation can be optimized
			for the specific needs of the supernet, ensuring high performance and low
			memory usage.

		\item \textbf{Control:} Direct control over the graph structure allows for
			easier debugging, customization, and integration with other system
			components.
	\end{itemize}

	\begin{figure}[H]
		\centering
		\includegraphics[angle=90, height=\textheight]{
			Figure/Agentic Workflow Class Diagram.png
		}
		\caption{Agentic Workflow Class Diagram}
		\label{fig:Agentic_Workflow_Class_Diagram}
	\end{figure}

	\paragraph{Supernet}
	The \textbf{Supernet} package is the core of the agentic workflow, responsible
	for orchestrating the flow of data and operations. Key components include:
	\begin{itemize}
		\item \texttt{ControllerNetwork}: A neural network (subclassing \texttt{torch.nn.Module})
			designed to infer and select appropriate operators within the supernet. The
			network designed for this ControllerNetwork has been mentioned in Section \ref{section:3.1_agentic_workflow_creation_framework}:
			Controller Network (Chapter \ref{chapter:Theoretical_foundation_of_agentic_workflow_framework}).

		\item \texttt{OperatorLayer} and \texttt{OperatorNode}: These classes
			represent layers and nodes (operators) within the supernet graph, enabling
			flexible composition of complex workflows.

		\item \texttt{AgenticOperator}: Encapsulates the logic of individual operators,
			each producing output in JSON format.

		\item \texttt{OutputParser}: Handles the correction and parsing of JSON outputs,
			ensuring robust downstream processing.
	\end{itemize}
	This modular design allows for flexible construction and modification of agentic
	workflows, supporting experimentation and rapid prototyping.
	\paragraph{Short-term Memory}
	The \textbf{Short-term Memory} package manages the agent's working memory, as
	described in section \ref{section:3.2_shorterm_memory_management}: Shorterm Memory
	Management (Chapter
	\ref{chapter:Theoretical_foundation_of_agentic_workflow_framework}). It
	includes:
	\begin{itemize}
		\item \texttt{MemoryStack}, \texttt{MemoryTopic}, \texttt{MemoryBlock}, \texttt{MemoryAtom},
			\texttt{MemoryWorker}: These classes collectively implement a hierarchical
			memory structure, supporting efficient storage, retrieval, and
			manipulation of short-term information.
	\end{itemize}
	This design enables the agent to maintain context and state across multiple operations,
	enhancing its ability to perform complex, multi-step tasks.

	\subsection{Sequence Diagram Analysis for Featured Usecases}
	\label{section:4.1.4_sequence_diagram_analysis_for_featured_usecases}
	\subsubsection{Usecase 1: Knowledge Retrieval Chat}
	This usecase demonstrates the implementation of a knowledge retrieval chat system
	that leverages document indexing and semantic search capabilities. The system
	enables teachers to upload course materials and students to interact with the
	content through natural language queries. We will analyze the sequence diagram
	to understand the interaction flow between different system components and how
	they work together to provide an efficient knowledge retrieval experience.

	\begin{figure}[H]
		\centering
		\includegraphics[width=\textwidth]{Figure/Knowledge Retrieval Chat.png}
		\caption{Knowledge Retrieval Chat Sequence Diagram}
		\label{fig:Knowledge_Retrieval_Chat_Sequence_Diagram}
	\end{figure}
	The document ingestion process is initiated by the teacher, who adds course
	materials through the FrontEnd interface. Upon receiving this request, the
	FrontEnd triggers the document indexing workflow by instructing the AI System
	to start indexing the newly added materials. The AI System, in turn, communicates
	with the OpenEdX Backend to retrieve the relevant course content. Once the
	materials are obtained, the AI System proceeds with the document indexing procedure,
	as detailed in the Document Indexing sub-diagram (see Figure~\ref{fig:Document_Indexing_Sequence_Diagram}).
	This process ensures that all instructional resources are systematically processed
	and made available for subsequent retrieval.

	In the knowledge retrieval phase, the student interacts with the system by
	submitting a question via the FrontEnd. The FrontEnd forwards the student's query
	to the AI System, which is responsible for orchestrating the retrieval of
	relevant knowledge. The AI System processes the question and invokes the Retrieves
	Knowledge workflow (see Figure~\ref{fig:Retrieves_Knowledge_Sequence_Diagram}),
	leveraging the previously indexed documents to generate an appropriate
	response. The answer is then relayed back to the student, thereby facilitating
	an efficient and interactive knowledge retrieval experience.

	\begin{figure}[H]
		\centering
		\includegraphics[width=\textwidth]{Figure/Document Indexing.png}
		\caption{Document Indexing Sequence Diagram}
		\label{fig:Document_Indexing_Sequence_Diagram}
	\end{figure}

	The Document Indexing sequence diagram (Figure~\ref{fig:Document_Indexing_Sequence_Diagram})
	details the workflow initiated when the AI System receives a request to start indexing
	newly uploaded document materials. The process begins with the AI System
	instructing Surya to upload the documents, which are then saved to MinIO for storage.
	Subsequently, the AI System coordinates with various components to process the
	documents: performing OCR, merging bounding boxes, and chunking the content
	via RAGFlow. Depending on the configuration, the system may extract keywords
	or generate cluster summaries using RAPTOR, with all extracted information and
	summaries being embedded and stored in ElasticSearch. If knowledge graph
	construction is enabled, entities and relationships are extracted and embedded,
	and the resulting graph is saved in the Graph Database. This comprehensive indexing
	pipeline ensures that all relevant document features are efficiently processed,
	embedded, and stored, thereby enabling robust and scalable knowledge retrieval
	in subsequent user interactions.

	\begin{figure}[H]
		\centering
		\includegraphics[width=\textwidth]{Figure/Retrieves Knowledge.png}
		\caption{Retrieves Knowledge Sequence Diagram}
		\label{fig:Retrieves_Knowledge_Sequence_Diagram}
	\end{figure}

	The Retrieves Knowledge sequence diagram (Figure~\ref{fig:Retrieves_Knowledge_Sequence_Diagram})
	illustrates the process by which the system responds to a user's query. Upon
	receiving an input query from the AI System, the Agentic Workflow component determines
	whether knowledge retrieval or additional data is required. If knowledge is
	needed, the workflow initiates a loop to retrieve relevant information from the
	Retrieval Service. If further data or external operations are necessary, the workflow
	enters a tool loop, invoking the Tool Ecosystem as needed. After gathering all
	required knowledge and data, the Agentic Workflow generates a comprehensive
	answer, which is then returned to the AI System for delivery to the user. This
	sequence ensures that responses are both contextually relevant and enriched
	with the most pertinent information available.

	\subsubsection{Usecase 2: MCP Integration}
	This usecase demonstrates the implementation of a MCP integration system that
	allows the system to interact with external tools and services. The system enables
	the agent to perform complex operations beyond pure language understanding. We
	will analyze the sequence diagram to understand the interaction flow between
	different system components and how they work together to provide an efficient
	MCP integration experience.

	\begin{figure}[H]
		\centering
		\includegraphics[angle=90, width=0.9\textwidth]{Figure/MCP Integration.png}
		\caption{MCP Integration Sequence Diagram}
		\label{fig:MCP_Integration_Sequence_Diagram}
	\end{figure}

	The integration of the MCP (Model Context Protocol) server into the Tool Ecosystem,
	as illustrated in Figure~\ref{fig:MCP_Integration_Sequence_Diagram}, provides a
	systematic approach for extending the agent system's capabilities through standardized
	tool interfaces. This process begins with the developer employing the
	OpenAPI2MCP converter application, which is designed to automatically translate
	an OpenAPI specification into a deployable MCP server instance. Following the
	creation of the MCP server, the developer utilizes the MCP Inspector to rigorously
	test and validate the server's functionality, ensuring that all endpoints and
	tool calls conform to the expected protocol and operational requirements. If the
	MCP server passes all validation checks, it can then be formally registered
	within the Tool Ecosystem, thereby making its services available for orchestration
	by the agentic workflow (see Section 4.1: Agent System Architecture). This integration
	not only facilitates seamless interoperability between newly developed tools and
	the existing system, but also supports iterative testing and refinement
	through the Developer Tool, as detailed in Section 4.4: Developer Tool
	Architecture. The entire workflow, from OpenAPI specification to tool
	registration, has been fully implemented and formalized, enabling developers
	to efficiently onboard and manage new tools within the broader system
	architecture.

	\section{E-learning Backend System Architecture}
	\label{section:4.2_e_learning_backend_system_architecture}
	\subsection{The Role of the Subsystem}
	\label{section:4.2.1_the_role_of_the_subsystem}
	\begin{condensed_idea}[The Role of the E-learning Backend System within the Thesis]
		The E-learning Backend System is composed of two main subsystems: the OpenEdX Backend and the AI Subsystem. The OpenEdX Backend, located in the Application Layer, provides the foundational Learning Management System (LMS) and Content Management System (CMS) functionalities. It ensures
		effective course management and content delivery. The AI Subsystem,
		described in Section \ref{section:4.1_agent_system_architecture}: Agent System
		Architecture (Chapter \ref{chapter:4_System_analysis_and_design}),
		integrates advanced AI capabilities to enhance intelligent assistance and
		personalized learning. By orchestrating agentic workflows and integrating sophisticated
		tools, it augments the educational platform's ability to perform complex
		reasoning tasks.
	\end{condensed_idea}

	\subsection{Overall design}
	\label{section:4.2.1_overall_design}

	The overall system architecture follows a microservice-based design pattern, as
	illustrated in Figure \ref{fig:EverLearn_Component_Diagram}. The architecture
	comprises three primary components that interact through well-defined
	interfaces to deliver a comprehensive e-learning experience enhanced with
	intelligent agent capabilities.

	\begin{figure}[H]
		\centering
		\includegraphics[width=0.9\textwidth]{
			Figure/EverLearn Component Diagram.png
		}
		\caption{EverLearn System Component Diagram}
		\label{fig:EverLearn_Component_Diagram}
	\end{figure}

	\subsubsection{Component Description and Dependencies}
	\label{section:4.2.1.1_component_description_and_dependencies} \textbf{OpenEdX
	Backend Component:} This component encapsulates the core educational platform
	functionality, comprising two sub-components:
	\begin{itemize}
		\item \textbf{LMSService (Learning Management System):} Responsible for
			course delivery, student progress tracking, assignment management, and assessment
			functionalities. This service maintains the core educational workflows and
			student data management.

		\item \textbf{CMSService (Content Management System):} Handles course
			content creation, editing, and organization. This service enables instructors
			to develop and manage educational materials, course structures, and learning
			resources.
	\end{itemize}

	\textbf{FrontendService Component:} This component serves as the primary user
	interface layer, providing a unified web-based interface for both learners and
	educators. The FrontendService acts as an orchestration layer that:
	\begin{itemize}
		\item Aggregates data from multiple backend services

		\item Presents a cohesive user experience

		\item Handles user authentication and session management

		\item Coordinates interactions between the traditional learning platform and
			the intelligent agent system
	\end{itemize}

	\textbf{AgentSystem Component:} This component implements a multi-agent instance
	built upon the framework proposed in Chapter \ref{chapter:Theoretical_foundation_of_agentic_workflow_framework} of this
	thesis. It provides intelligent assistance capabilities including automated
	question answering, and search over learning materials.

	\subsubsection{Interface and Communication Patterns}
	\label{section:4.2.1.2_interface_and_communication_patterns} The component diagram
	reveals three critical communication interfaces:

	\textbf{LearningInformation Interface:} This interface facilitates the
	bidirectional exchange of educational data between the FrontendService and
	OpenEdX Backend.

	\textbf{MakeToolCall Interface:} This interface enables the \fcolorbox{gray!50}{gray!10}{\texttt{AgentSystem}} to make
	tool requests to OpenEdX backend service to retrieve necessary data (learning
	materials, course content, etc.) \textbf{AgentResponse Interface:} This interface
	delivers processed results from the AgentSystem back to the FrontendService,
	enabling:
	\begin{itemize}
		\item Structured response formatting for user interface integration

		\item Multi-modal content delivery (text, recommendations, explanations)

		\item Error handling and fallback response mechanisms
	\end{itemize}

	\subsubsection{Architectural Design Principles}
	\label{section:4.2.1.3_architectural_design_principles}

	The architecture of the \fcolorbox{gray!50}{gray!10}{\texttt{E-learning Backend System adheres to several key design
	principles, ensuring a robust and efficient platform:

	\textbf{Separation of Concerns:} Each component is designed with distinct responsibilities.
	The OpenEdX Backend manages traditional e-learning operations, the \fcolorbox{gray!50}{gray!10}{\texttt{AgentSystem}}
	handles intelligent assistance, and the FrontendService orchestrates user
	interactions. This separation ensures clarity and focus in each component's functionality.

	\textbf{Loose Coupling:} Components interact solely through well-defined
	interfaces, allowing for independent development, deployment, and scaling.
	This design minimizes dependencies and enhances the system's flexibility and
	resilience.

	\textbf{Layered Dependencies:} The architecture follows a clear hierarchy of dependencies.
	The FrontendService depends on both backend services, while the OpenEdX Backend
	and AgentSystem remain independent of each other, preventing circular
	dependencies and ensuring stability.

	\textbf{Scalability and Extensibility:} The microservice structure supports independent
	scaling of components based on load characteristics. It also allows for future
	extensions with additional agent capabilities or educational services, ensuring
	the system can grow and adapt over time.

	This architectural design ensures that the integration of advanced AI capabilities
	through the AgentSystem enhances, rather than disrupts, the established educational
	workflows provided by the OpenEdX platform. It maintains system reliability
	and performance, supporting a seamless and effective educational experience.

	\textbf{Software Architecture Selection:} The e-learning system developed in
	this thesis integrates the OpenEdX backend with an agent system built upon the
	proposed framework, adopting a microservice architecture as the optimal pattern.
	This choice is supported by several critical considerations:

	\begin{enumerate}
		\item \textbf{Independent Scalability:} The microservice architecture allows
			each component to scale independently based on specific load
			characteristics, optimizing resource utilization during periods of high learning
			activity.

		\item \textbf{Technological Heterogeneity:} The architecture accommodates
			diverse technologies optimized for specific functional domains, eliminating
			technological dependencies between components.

		\item \textbf{Enhanced Maintainability and Development Agility:} The system's
			decomposition into focused, loosely-coupled services enhances maintainability
			and facilitates continuous development, minimizing system downtime and
			operational risk.

		\item \textbf{Fault Isolation and System Resilience:} Microservices provide
			superior fault isolation capabilities, ensuring that failures within the agent
			system components do not compromise the core educational platform's integrity.

		\item \textbf{Integration Flexibility and Extensibility:} The architecture
			facilitates seamless integration between OpenEdX and the agent system
			through well-defined APIs, supporting future modifications and enhancements.

		\item \textbf{Parallel Development and Team Autonomy:} The architectural
			pattern enables concurrent development of different system components by
			independent teams, resulting in accelerated development cycles and improved
			efficiency.
	\end{enumerate}

	The microservice architecture aligns with the evolutionary nature of e-learning
	platforms, allowing for the gradual addition of new features and services as
	pedagogical needs evolve. This choice provides a robust, scalable, and maintainable
	foundation for integrating both established learning management capabilities and
	innovative AI-driven features.

	\subsection{Detailed Component Design}
	\label{section:4.2.2_detailed_component_design} The OpenEdX Backend Component represents
	the foundational educational platform infrastructure, implementing a
	comprehensive LMS and CMS
	architecture. This component leverages the established OpenEdX framework,
	which follows a Django-based Model-View-Controller (MVC) architectural pattern
	with several key design considerations.

	\textbf{Architectural Foundation:} The OpenEdX backend employs a modular,
	plugin-based architecture built on Django framework, enabling extensibility and
	customization while maintaining core functionality stability. The system is
	structured around two primary services that operate as distinct but
	interconnected applications:

	\begin{figure}[H]
		\centering
		\includegraphics[width=\textwidth]{Figure/open-edx-architecture.jpeg}
		\caption{OpenEdX Backend Component}
		\label{fig:OpenEdX_Backend_Component}
	\end{figure}

	\subsubsection{LMSService (Learning Management System) Design}
	\label{section:4.2.2.1_lmservice_learning_management_system_design} The \fcolorbox{gray!50}{gray!10}{\texttt{LMSService}}
	implements the student-facing learning environment and encompasses several critical
	subsystems:

	\begin{itemize}
		\item \textbf{Course Runtime Engine:} Manages course delivery, sequencing,
			and navigation logic. This engine processes learning paths, handles
			prerequisite validation, and ensures proper content progression based on course
			structure definitions.

		\item \textbf{Assessment and Grading System:} Implements a comprehensive
			evaluation framework supporting multiple question types (multiple choice,
			short answer, programming assignments, peer assessments). The grading
			system employs both automated and manual grading workflows with support
			for custom grading policies and rubrics.

		\item \textbf{Student Progress Tracking:} Maintains detailed learning
			analytics including completion rates, time spent on activities,
			performance metrics, and learning outcome achievement. This subsystem
			provides real-time progress monitoring and historical data aggregation.

		\item \textbf{Discussion and Collaboration Framework:} Facilitates student-instructor
			and peer-to-peer interactions through threaded discussion forums, real-time
			messaging, and collaborative workspaces. The framework supports moderation,
			content filtering, and engagement analytics.

		\item \textbf{Certificate and Credential Management:} Handles the generation,
			validation, and distribution of course completion certificates and digital
			credentials, including integration with blockchain-based verification systems.
	\end{itemize}

	\subsubsection{CMSService (Content Management System) Design}
	\label{section:4.2.2.2_cmservice_content_management_system_design} The
	\fcolorbox{gray!50}{gray!10}{\texttt{CMSService}} provides the authoring environment for course creators and
	instructors, featuring:

	\begin{itemize}
		\item \textbf{Course Authoring Tools:} A comprehensive suite of content
			creation interfaces supporting multimedia integration, interactive components,
			and assessment design. The authoring environment employs a block-based editing
			system that enables modular content development.

		\item \textbf{Content Repository and Version Control:} Manages course assets,
			multimedia files, and content versioning with support for collaborative
			editing, branch management, and rollback capabilities. The repository implements
			efficient storage optimization and content delivery network (CDN) integration.

		\item \textbf{Course Structure Management:} Provides hierarchical course
			organization tools for defining learning sequences, modules, units, and individual
			components. The structure management system supports complex prerequisite
			relationships and adaptive learning paths.

		\item \textbf{Publishing and Release Management:} Controls content
			publication workflows, enabling staged releases, A/B testing, and scheduled
			content activation. The system maintains separation between draft and
			published content with comprehensive preview capabilities.
	\end{itemize}

	\textbf{Data Architecture and Persistence:} The OpenEdX backend employs a hybrid
	data storage strategy combining relational databases (MySQL/PostgreSQL) for structured
	educational data and NoSQL solutions (MongoDB) for flexible content storage.
	Key data management features include:

	\begin{itemize}
		\item \textbf{Relational Data Management:} Student enrollment records, course
			metadata, grading information, and user authentication data are maintained
			in normalized relational structures ensuring data integrity and consistency.

		\item \textbf{Content Storage Optimization:} Course content, multimedia assets,
			and user-generated content utilize document-based storage with efficient
			indexing and retrieval mechanisms optimized for content delivery
			performance.

		\item \textbf{Analytics Data Pipeline:} Implements event-driven data
			collection and processing pipelines for learning analytics, capturing detailed
			interaction logs, performance metrics, and engagement patterns.
	\end{itemize}

	\subsubsection{API Architecture and Integration Points}
	\label{section:4.2.2.3_api_architecture_and_integration_points} The OpenEdX backend
	exposes a comprehensive RESTful API architecture enabling external system integration:

	\begin{itemize}
		\item \textbf{Course API:} Provides programmatic access to course
			information, enrollment management, and content retrieval, enabling the AgentSystem
			to access learning materials and course metadata.

		\item \textbf{User API:} Manages user authentication, profile information,
			and learning progress data, supporting single sign-on (SSO) integration and
			external identity providers.

		\item \textbf{Grades API:} Enables access to assessment results, grade book information,
			and performance analytics, facilitating intelligent tutoring and personalized
			feedback generation.
	\end{itemize}

	\textbf{Scalability and Performance Considerations:} The OpenEdX backend architecture
	incorporates several scalability mechanisms:

	\begin{itemize}
		\item \textbf{Horizontal Scaling:} Support for load balancing across
			multiple application servers with session affinity management and
			distributed caching strategies.

		\item \textbf{Database Optimization:} Implementation of read replicas, query
			optimization, and database sharding strategies to handle large-scale
			educational deployments.

		\item \textbf{Content Delivery:} Integration with content delivery networks
			(CDN) for efficient multimedia content distribution and reduced server
			load.
	\end{itemize}

	This architectural design ensures that the OpenEdX backend provides a robust, scalable
	foundation for educational content delivery while maintaining the flexibility necessary
	for integration with the intelligent AgentSystem component.

	\section{E-learning Frontend Service Architecture}
	\label{section:4.3_e_learning_frontend_service_architecture}

	\subsection{The Role of the Subsystem}
	\label{section:4.3.1_the_role_of_the_subsystem}
	\begin{condensed_idea}[The Role of the E-learning Frontend Service within the Thesis]
		The Frontend Service Component, situated within the Application Layer, serves as the primary user interface of the e-learning platform. Built upon the E-learning Backend System described in Section \ref{section:4.2_e_learning_backend_system_architecture}: E-learning Backend System Architecture (Chapter \ref{chapter:System_anaylsis_and_design}), it acts as the main point of interaction for both learners and instructors. Utilizing NextJS, a modern React framework, the design emphasizes usability, responsiveness, and seamless integration with backend services, ensuring a cohesive and engaging educational experience.
	\end{condensed_idea}

	The Frontend Service plays a crucial role in the overall architecture of the e-learning
	platform by acting as the primary interface through which users interact with the
	system. It is responsible for rendering all user-facing pages and components, including
	course catalogs, dashboards, learning modules, assessments, and progress tracking
	interfaces. By leveraging the capabilities of NextJS, the Frontend Service ensures
	that the user experience is both intuitive and efficient, providing real-time
	updates and seamless navigation across different sections of the platform. Additionally,
	it manages user authentication, session persistence, and access control, ensuring
	secure and personalized access to educational resources. The Frontend Service
	also facilitates communication with the backend services, including the OpenEdX
	Backend and the AI Subsystem, to deliver intelligent assistance and
	personalized learning experiences. Through its comprehensive integration with these
	backend components, the Frontend Service not only enhances the usability and
	accessibility of the platform but also supports the delivery of innovative AI-driven
	features, thereby enriching the overall educational experience for learners and
	instructors alike.

	\subsection{Overview of the Frontend Service}
	\label{section:4.3.1.1_overview_of_the_frontend_service}
	\subsubsection{Component Description and Dependencies}
	\label{section:4.3.1.1_component_description_and_dependencies} The FrontendService
	is structured around several core components with specific responsibilities:

	\begin{itemize}
		\item \textbf{User Interface Layer:} Responsible for rendering all user-facing
			pages and components, including course catalogs, dashboards, learning modules,
			assessments, and progress tracking interfaces.

		\item \textbf{Authentication Layer:} Manages user authentication, session persistence,
			and access control, supporting secure login, registration.

		\item \textbf{API Integration Layer:} Handles communication with backend
			services, including OpenEdX Backend and AgentSystem.
	\end{itemize}

	The component depends on:
	\begin{itemize}
		\item OpenEdX Backend for core educational functionality

		\item AgentSystem for intelligent assistance features

		\item Authentication services for user management

		\item CDN services for static asset delivery
	\end{itemize}

	\subsubsection{Interface and Communication Patterns}
	\label{section:4.3.1.2_interface_and_communication_patterns} The
	FrontendService implements several key interfaces for system integration:

	\begin{itemize}
		\item \textbf{LearningInformation Interface:} Facilitates bidirectional data
			exchange with OpenEdX Backend for course content, user data, and
			assessment results.

		\item \textbf{AgentResponse Interface:} Processes and displays intelligent
			responses from the AgentSystem, including contextual hints and personalized
			recommendations.

		\item \textbf{Authentication Interface:} Handles user authentication flows
			and session management.
	\end{itemize}

	\subsection{Detailed Component Design}
	\label{section:4.3.2_detailed_component_design}
	\subsubsection{UI Interface Layer}
	\label{section:4.3.2.1_ui_interface_layer} \textbf{Layout Components}

	The \fcolorbox{gray!50}{gray!10}{\texttt{Root Layout}} component serves as the
	fundamental structural framework for the entire application, implementing a
	responsive and modern design pattern. It utilizes a \texttt{ThemeProvider} to
	enable dynamic theme switching between light and dark modes, with system preference
	detection capabilities. The layout is structured in a vertical flex container
	that spans the full viewport height, featuring a sticky navigation bar at the top
	that remains fixed during scrolling, a flexible main content area that grows
	to fill available space, and a footer that automatically positions itself at the
	bottom. The component also incorporates a custom scrollbar for enhanced user
	experience and includes a toast notification system positioned at the bottom-right
	corner of the screen, which provides non-intrusive feedback to users through smooth
	zoom transitions. This layout architecture ensures consistent navigation and
	user interface elements across all pages while maintaining a clean and
	organized visual hierarchy.

	\lstinputlisting[style=htmlcssjs, caption=Root Layout Component]{Code/root_layout_component.html}

	\textbf{AI Chat Interface}

	The \fcolorbox{gray!50}{gray!10}{\texttt{AI Chat Sidebar}} component provides
	a versatile chat interface that can operate in two distinct modes: as a floating
	panel or integrated within the main content area. The component features a
	toggle mechanism for visibility control, allowing users to show or hide the interface
	as needed. A key aspect of the interface is its dual-mode chat functionality, enabled
	through a dropdown selector that allows users to switch between \emph{standard
	QnA chat} and \emph{agent-assisted chat} modes. Additionally, the component includes
	a model selection dropdown, enabling users to choose from different AI models
	for their interactions. The chat window is designed to display AI responses with
	their corresponding reference materials, which are automatically attached and
	displayed below each response message for enhanced context and verification.

	\lstinputlisting[style=htmlcssjs, caption=AI Chat Sidebar Component Layout]{Code/ai_chat_sidebar.html}

	\textbf{Document Preview Component}

	The \fcolorbox{gray!50}{gray!10}{\texttt{Document Preview}} component
	implements a sophisticated PDF document viewer using the React-PDF library. The
	component features an interactive canvas that supports automatic scrolling functionality,
	enabling seamless navigation through document content. A key feature of this component
	is its ability to render citation bounding boxes, which visually highlight
	referenced content within the PDF document. This functionality is integrated with
	the knowledge citation system, as detailed in the Knowledge Citation sequence
	diagram, allowing for precise visualization of cited information. The
	component maintains synchronization between the displayed document and the
	citation system, ensuring accurate representation of referenced content while providing
	a smooth user experience for document navigation and citation review.

	For more detailed descrition of UI components, please refer to the Appendix
	\ref{appendix:e_ui_components}: Detailed Implementation of UI Components.

	\subsubsection{Authentication Layer}
	\label{section:4.3.2.2_authentication_layer}

	The authentication system is built on a sophisticated architecture that
	prioritizes security and user experience. The core of the system is the \texttt{createAuthApi}
	factory function, which creates a configured Axios instance with built-in security
	features. This instance is enhanced with three essential interceptors:

	\begin{itemize}
		\item \emph{\textbf{A JWT token provider interceptor}} that automatically
			manages access token refresh

		\item \emph{\textbf{A CSRF token provider interceptor}} that handles CSRF
			token acquisition and attachment

		\item \emph{\textbf{A request error interceptor}} that processes
			authentication-related errors
	\end{itemize}

	The system maintains two separate API instances to handle different types of requests:
	\begin{itemize}
		\item \emph{\textbf{A public instance}} for unauthenticated operations such
			as registration validation and username suggestions

		\item \emph{\textbf{An authenticated instance}} that automatically manages
			token handling and security headers
	\end{itemize}

	The implementation includes several key features:
	\begin{itemize}
		\item Comprehensive error handling with specific error types for different failure
			scenarios

		\item Environment-based configuration management for flexible deployment

		\item Robust input validation using Zod schemas for type safety

		\item Automatic token refresh mechanism for seamless authentication

		\item Protection against common web vulnerabilities through secure cookie handling
			and CSRF protection
	\end{itemize}

	This architecture ensures a secure and reliable authentication system while providing
	a smooth user experience through automated token management and comprehensive error
	handling.

	\subsubsection{Knowledge Citation System}
	\label{section:4.3.2.3_knowledge_citation_system}

	\begin{figure}[H]
		\centering
		\includegraphics[width=\textwidth]{Figure/Knowledge Citation.png}
		\caption{Knowledge Citation System}
		\label{fig:Knowledge_Citation_System}
	\end{figure}

	The sequence diagram in Figure~\ref{fig:Knowledge_Citation_System} details the
	operational flow of the knowledge citation system, which enables users to
	trace AI-generated responses back to their original document sources. The process
	begins when a student submits a chat message through the \fcolorbox{gray!50}{gray!10}{\texttt{AI
	Chat Sidebar}} interface. This message is immediately forwarded to the AI
	System, which is responsible for retrieving relevant knowledge from a designated
	knowledge base. During this retrieval process, the AI System not only extracts
	the pertinent content but also determines the exact location of the cited information
	within the source document, including the page number and the bounding box
	coordinates that delineate the referenced text or region.

	These positional data—comprising both the page number and bounding box—are
	returned alongside the retrieved knowledge and are temporarily stored within
	the active chat session. This storage ensures that the citation metadata remains
	accessible for subsequent user interactions. When the student clicks on a
	reference link or citation within the chat interface, a preference event is triggered,
	prompting the system to initiate the creation of a
	\fcolorbox{gray!50}{gray!10}{\texttt{Document Preview}} panel. The \fcolorbox{gray!50}{gray!10}{\texttt{Document
	Preview}} component is then instantiated and acknowledges its readiness to display
	the requested content.

	Upon activation, the \fcolorbox{gray!50}{gray!10}{\texttt{Document Preview}}
	component receives the stored citation metadata and utilizes it to render a
	visual highlight directly on the document canvas. Specifically, the component
	draws a bounding box around the cited content and automatically scrolls to the
	corresponding page, providing immediate visual context for the referenced material.
	This tightly integrated workflow allows users to seamlessly transition from AI-generated
	answers to the precise location of supporting evidence within the source
	document, thereby enhancing the transparency, traceability, and trustworthiness
	of the system's responses.

	\section{Developer Tool Architecture}
	\label{section:4.4_developer_tool_architecture}
	\subsection{The Role of the Subsystem}
	\label{section:4.4.1_the_role_of_the_subsystem}
	\begin{condensed_idea}[The Role of Developer Tool within the Thesis]
		The Developer Tool Component, situated within the AI System Layer, serves as the centralized tool for developers and testers to develop, test and debug the AI system (see Section \ref{section:4.1_ai_system_architecture}: AI System Architecture). It provides three core functions: (1) MCP integration, offering a standardized workflow for converting, inspecting, and registering tools into the AI System's Tool Ecosystem; (2) benchmarking dataset generation and editing with strict version control, enabling robust evaluation of Retrieval-Augmented Generation (RAG) performance on private datasets; and (3) direct AI system testing, allowing developers and testers to validate tool integration and system capabilities in a controlled development environment prior to production deployment.
	\end{condensed_idea}

	The Developer Tool Component is a critical subsystem within the AI System Layer, designed to facilitate the efficient development, integration, and evaluation of AI-driven functionalities. Its MCP (Modular Command Protocol) integration capabilities provide a standardized workflow for incorporating new tools into the Tool Ecosystem, supporting essential operations such as OpenAPI-to-MCP conversion, MCP inspection, and MCP registration, as detailed in Use Case 2: MCP Integration (see Section~\ref{section:4.1.4_sequence_diagram_analysis_for_featured_usecases}). In addition, the Developer Tool supports the generation and editing of benchmarking datasets under strict version control, addressing the need for rigorous performance assessment of Retrieval-Augmented Generation (RAG) systems on proprietary, business-specific data rather than public datasets. This ensures that the AI system's retrieval and generation capabilities are thoroughly validated in real-world scenarios. Furthermore, the Developer Tool is directly connected to a development instance of the AI system, enabling comprehensive testing of tool integration, RAG performance, and related functionalities in a safe, non-production environment. This integrated approach ensures that only thoroughly tested and validated features are promoted to the production environment, thereby enhancing the reliability, maintainability, and overall quality of the AI system.

	\subsection{Frontend Design}
	\label{section:4.4.2_frontend_design}
	The FrontEnd of Developer Tool is structured in a layered manner, with the core components as defined below:
	\begin{itemize}
		\item \emph{\textbf{User Interface Layer}} (see \ref{section:4.4.2.1_user_interface_layer}): The user interface layer is the outermost layer of the Developer Tool, and it is responsible for the overall structure and layout as well as UI design of the Developer Tool.
		\item \emph{\textbf{Authentication Layer}} (see \ref{section:4.4.2.2_authentication_layer}): The authentication layer is the middle layer of the Developer Tool, and it is responsible for the authentication and user role management of the Developer Tool.
		\item \emph{\textbf{API Integration Layer}} (see \ref{section:4.4.2.3_api_integration_layer}): The API integration layer is the middle layer of the Developer Tool, and it is responsible for the communication between the Developer Tool and the backend system.
	\end{itemize}

	\subsubsection{User Interface Layer}
	\label{section:4.4.2.1_user_interface_layer}
	The User Interface Layer of Developer Tool is built with NextJS, a modern React framework, and Tailwind CSS, a utility-first CSS framework. It consists of several key UI components as defined below:
	\begin{itemize}
		\item \emph{\textbf{Layout Components}}: The layout components constitute the fundamental structural framework of the Developer Tool. These components dynamically adapt the interface layout based on user privileges, which are managed and assigned by the backend system.
		
		\item \emph{\textbf{AI Chat Interface}}: The AI chat interface serves as a comprehensive testing environment for the AI system's capabilities. This interface facilitates the evaluation and demonstration of various AI functionalities, including function calling mechanisms, step-by-step reasoning processes, and document retrieval operations.
		
		\item \emph{\textbf{MCP Integration Interface}}: The MCP integration interface provides a systematic workflow for tool integration within the AI System's Tool Ecosystem. This interface streamlines the processes of tool conversion, inspection, and registration, enabling developers to efficiently test and debug MCP servers without the need for complex command-line operations.
		
		\item \emph{\textbf{Benchmarking Dataset Generation Interface}}: The benchmarking dataset generation interface implements a standardized methodology for creating, modifying, and maintaining benchmarking datasets for the AI system. This interface incorporates a version control system to ensure dataset reproducibility and maintain comprehensive traceability throughout the development process.
	\end{itemize}

	\paragraph{Layout Components} The layout components implement a minimalist design approach utilizing the shadcn.ui component library. The interface features a streamlined navigation bar containing three primary navigation buttons: "Benchmarking", "MCP", and "AI Chat". This simplified structure ensures efficient user navigation while maintaining a clean, modern aesthetic.
	\paragraph{AI Chat Interface} The AI Chat Interface extends the functionality of the E-learning Frontend's AI chat sidebar (see Section \ref{section:4.3_e_learning_frontend_service_architecture}) with enhanced visualization capabilities for internal processes. The interface comprises three primary panels: a chat interaction panel, a document preview panel, and a tool execution history panel. The document preview panel incorporates the knowledge citation system (see Section \ref{section:4.3.2.3_knowledge_citation_system}), enabling users to trace information sources. The tool execution history panel provides a detailed, step-by-step visualization of the tool execution process for each message, offering transparency into the AI system's decision-making workflow. Additionally, the interface includes a session management panel that facilitates the organization and tracking of conversation contexts. This comprehensive design enables developers to effectively monitor, debug, and understand the AI system's operations while maintaining the familiar chat interaction paradigm.
	\paragraph{MCP Integration Interface} The MCP Integration Interface consists of two specialized components: the OpenAPI Editor and the MCP Debugger. The OpenAPI Editor provides a dedicated YAML-based Integrated Development Environment (IDE) for OpenAPI specification development, incorporating version control capabilities to track specification changes. This component exclusively supports YAML format for OpenAPI specifications, ensuring compliance with the system's requirements. The MCP Debugger, built upon the official MCP Inspector UI, offers a comprehensive debugging environment for MCP server interactions.
	\paragraph{Benchmarking Dataset Generation Interface} The Benchmarking Dataset Generation Interface provides a comprehensive dataset management system centered around a tabular viewer, where each row represents an individual test question. The interface supports both granular and batch operations: testers can modify individual test questions through direct row editing, or perform bulk modifications by selecting multiple rows and providing a natural language prompt that triggers the test case regeneration workflow. This workflow automatically processes the specified modifications across the selected test cases. Additionally, the interface incorporates a version control system with a dedicated commit interface, enabling testers to maintain a structured history of dataset changes and ensuring reproducibility of test scenarios.


	\subsubsection{Authentication Layer}
	\label{section:4.4.2.2_authentication_layer}
	The Authentication Layer implements a streamlined security model designed for local network deployment, distinguishing it from the more complex authentication system of the E-learning platform. The layer employs a binary role-based access control (RBAC) system with two distinct user roles: "developer" and "tester". The "developer" role is granted comprehensive access to all system functionalities, including the MCP Integration Interface, AI Chat Interface, and Benchmarking Dataset Generation Interface, with full privileges for dataset creation and modification. In contrast, the "tester" role is restricted to two primary interfaces: the AI Chat Interface and the Benchmarking Dataset Generation Interface. Within the Benchmarking Dataset Generation Interface, testers are limited to modifying existing test data within generated datasets, without the capability to create new test datasets. This simplified authentication model aligns with the tool's local network deployment context while maintaining appropriate access controls for different user responsibilities.
	
	
	\subsection{Backend Design}
	\label{section:4.4.3_backend_design}

	\subsubsection{Database Design}
	\label{section:4.4.3.1_database_design}
	The database design of the Developer Tool is based on the SQLite database. The database is used to store the data of the Developer Tool, including the user information, the tool information, the dataset information, etc.

	\begin{figure}[H]
		\centering
		\includegraphics[width=\textwidth]{Figure/DB Design Dev Tool.png}
		\caption{Database Design of the Developer Tool}
		\label{fig:Database_Design}
	\end{figure}
	The database schema for the Developer Tool is designed to support robust user management, dataset organization, and comprehensive version control for benchmarking and testing workflows.
	Each user is uniquely identified and authenticated via a combination of username, password, and email address, as represented in the users table. This enables secure login and personalized access to the system.
	Datasets are managed through the \texttt{datasets} table, where each dataset is associated with a specific user and can contain multiple data rows. The \texttt{dataset\_rows} table captures the granular details of each test case or data entry within a dataset. Each row includes attributes such as \texttt{dataset\_id}, \texttt{document\_id}, \texttt{chunk\_id}, \texttt{metadata}, \texttt{question}, \texttt{direct\_answer}, \texttt{retrieved\_chunks}, and \texttt{augmented\_answer}, providing a flexible structure for storing both the original and processed information relevant to each test scenario.
	To ensure traceability and reproducibility, the system incorporates a version control mechanism. Users can create commits, each accompanied by a commit message, to record changes made to any dataset rows. The \texttt{commits} and \texttt{dataset\_commits} tables track these commit events, while the \texttt{row\_versions} table maintains a detailed history of modifications at the row level, including the old and new data, type of change, timestamp, and the user responsible for the change. This architecture enables users to audit, revert, and manage the evolution of datasets over time, supporting collaborative and transparent development and testing processes.
	
	\subsubsection{Benchmarking Dataset Generation}
	\label{section:4.4.3.2_benchmarking_dataset_generation}
	The benchmarking dataset generation workflow is a critical component for ensuring the quality and robustness of the Retrieval-Augmented Generation (RAG) system's evaluation process. This workflow is structured into two distinct phases. In the initial phase, developers are responsible for generating the core benchmarking datasets, defining the structure and content of test cases to comprehensively assess RAG system performance. In the subsequent phase, testers engage in the iterative improvement of these test cases, refining and enhancing the dataset based on empirical results and observed system behavior. This two-phase approach ensures that the benchmarking datasets remain both comprehensive and representative, supporting rigorous and continuous evaluation of the RAG system.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=\textwidth]{Figure/Benchmarking Dataset Generation.png}
		\caption{Benchmarking Dataset Generation}
		\label{fig:Benchmarking_Dataset_Generation}
	\end{figure}

	\paragraph{\emph{\textbf{Dataset Generation Phase (by Developers)}}} In the initial phase of the benchmarking dataset generation workflow, developers are responsible for constructing the foundational dataset that will be used to evaluate the Retrieval-Augmented Generation (RAG) system. This process begins with the formalization of test case requirements, where developers specify the criteria and objectives for the dataset. Once the requirements are established, developers initiate a generation request through the Developer Tool, which orchestrates the workflow by forwarding the request to the Retrieval Service. The Retrieval Service aggregates all relevant document chunks and coordinates with the Agentic Workflow component to generate question-and-answer pairs for each chunk. This involves iterative retrieval of knowledge and the synthesis of answers, ensuring that each test case is both contextually relevant and comprehensive. Upon completion, the generated dataset is stored in the database, and developers are prompted to review and confirm the dataset, ensuring its alignment with the original requirements and the intended evaluation objectives.

	\paragraph{\emph{\textbf{Test Case Improvement Phase (by Testers)}}} Following the initial dataset creation, the workflow transitions to the test case improvement phase, which is primarily managed by testers. In this phase, testers iteratively refine and enhance the quality of the test cases based on empirical evaluation and observed system performance. Testers submit improvement requests, typically targeting specific questions or sets of questions within the dataset. These requests are processed by the Developer Tool and forwarded to the Retrieval Service, which again leverages the Agentic Workflow to update and improve the selected test cases. The process involves re-retrieving relevant knowledge, generating improved answers, and summarizing the results to ensure clarity and accuracy. Each modification is tracked, and testers are able to commit their changes, with all updates and version control information being persistently stored in the database. This iterative improvement cycle ensures that the benchmarking dataset remains up-to-date, comprehensive, and reflective of real-world evaluation needs, thereby supporting the continuous and rigorous assessment of the RAG system.
\end{document}